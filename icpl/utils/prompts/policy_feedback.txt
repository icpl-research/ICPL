We trained a RL policy using {response_index} reward function code and tracked the values of the individual components in the reward function as well as global metric episode_lengths after every {epoch_freq} epochs and the maximum, mean, minimum values encountered:
